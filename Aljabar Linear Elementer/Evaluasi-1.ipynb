{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230a5886",
   "metadata": {},
   "source": [
    "# üè≠ Predicting Profit from Advertising Spend Using Projection-Based Linear Regression\n",
    "\n",
    "---\n",
    "## üìò Introduction\n",
    "\n",
    "Linear regression is one of the simplest and most widely used methods in data analysis and machine learning. It helps us understand the relationship between two or more variables ‚Äî for example, how advertising spend affects product profit.\n",
    "\n",
    "In simple terms, linear regression draws a straight line that best fits the data. This line allows us to make predictions: if we know the input (like ad spend), we can estimate the output (like profit).\n",
    "\n",
    "But behind this simple idea, there's a powerful mathematical concept from linear algebra: **projection**.\n",
    "\n",
    "In this project, we look at linear regression from a geometric point of view. Instead of just finding the \"best line,\" we treat it as a process of projecting one vector (the output) onto the space formed by other vectors (the inputs). This gives us a deeper understanding of how regression works and why it gives the results it does.\n",
    "\n",
    "By combining statistics and linear algebra, we not only predict better ‚Äî we also **understand better**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìê Linear Regression Formula\n",
    "\n",
    "The general form of a simple linear regression model is:\n",
    "\n",
    "$$\n",
    "Y = a + bX + \\varepsilon\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $Y$: dependent variable (response)  \n",
    "- $X$: independent variable (predictor)  \n",
    "- $a$: intercept (value of $Y$ when $X = 0$)  \n",
    "- $b$: slope (change in $Y$ per unit change in $X$)  \n",
    "- $\\varepsilon$: error term  \n",
    "\n",
    "In matrix form:\n",
    "\n",
    "$$\n",
    "y = X\\beta + \\varepsilon\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $y$: vector of outputs  \n",
    "- $X$: matrix of inputs  \n",
    "- $\\beta$: vector of coefficients  \n",
    "- $\\varepsilon$: error vector  \n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Linear Regression as a Projection\n",
    "\n",
    "The goal is to find the **best linear approximation** of $y$ in the column space of $X$ by projecting $y$ onto that space.\n",
    "\n",
    "The predicted values $\\hat{y}$ lie in the subspace spanned by the columns of $X$, and this projection minimizes the squared distance from $y$ to the subspace.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Mathematical Formulation\n",
    "\n",
    "The normal equation gives the regression coefficients:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y\n",
    "$$\n",
    "\n",
    "The prediction is:\n",
    "\n",
    "$$\n",
    "\\hat{y} = X \\hat{\\beta} = X (X^\\top X)^{-1} X^\\top y\n",
    "$$\n",
    "\n",
    "Define the **projection matrix**:\n",
    "\n",
    "$$\n",
    "P = X (X^\\top X)^{-1} X^\\top\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\hat{y} = P y\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## üìê Properties of the Projection Matrix\n",
    "\n",
    "- $P$ is **idempotent**: $P^2 = P$\n",
    "- $P$ is **symmetric**: $P^\\top = P$\n",
    "- The residual $r = y - \\hat{y}$ is **orthogonal** to the column space of $X$:\n",
    "\n",
    "$$\n",
    "X^\\top r = 0\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495231fb",
   "metadata": {},
   "source": [
    "## üè≠ Case Study: Predicting Profit from Advertising Spend\n",
    "\n",
    "### üìå Problem\n",
    "\n",
    "A company wants to understand how advertising spending affects product profit. It collects data from 7 recent campaigns:\n",
    "\n",
    "| Campaign | Ad Spend ($X$, in \\$1,000s) | Profit ($Y$, in \\$1,000s) |\n",
    "|----------|------------------------------|----------------------------|\n",
    "| A        | 2                            | 65                         |\n",
    "| B        | 3                            | 70                         |\n",
    "| C        | 5                            | 75                         |\n",
    "| D        | 7                            | 85                         |\n",
    "| E        | 1                            | 60                         |\n",
    "| F        | 4                            | 72                         |\n",
    "| G        | 6                            | 78                         |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Build Vectors\n",
    "\n",
    "Let:\n",
    "\n",
    "- $X$ be the design matrix with intercept\n",
    "- $y$ be the vector of profits\n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\\\\\n",
    "1 & 3 \\\\\\\\\n",
    "1 & 5 \\\\\\\\\n",
    "1 & 7 \\\\\\\\\n",
    "1 & 1 \\\\\\\\\n",
    "1 & 4 \\\\\\\\\n",
    "1 & 6\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "y =\n",
    "\\begin{bmatrix}\n",
    "65 \\\\\\\\\n",
    "70 \\\\\\\\\n",
    "75 \\\\\\\\\n",
    "85 \\\\\\\\\n",
    "60 \\\\\\\\\n",
    "72 \\\\\\\\\n",
    "78\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Compute $\\hat{\\beta}$\n",
    "\n",
    "Using:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y\n",
    "$$\n",
    "\n",
    "Compute:\n",
    "\n",
    "$$\n",
    "X^\\top X =\n",
    "\\begin{bmatrix}\n",
    "7 & 28 \\\\\n",
    "28 & 140\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "X^\\top y =\n",
    "\\begin{bmatrix}\n",
    "505 \\\\\n",
    "2065\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "(X^\\top X)^{-1} =\n",
    "\\begin{bmatrix}\n",
    "1.4286 & -0.2857 \\\\\n",
    "-0.2857 & 0.0714\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} =\n",
    "\\begin{bmatrix}\n",
    "57 \\\\\n",
    "3.79\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Predict Profits\n",
    "\n",
    "Use:\n",
    "\n",
    "$$\n",
    "\\hat{y} = 57 + 3.79x\n",
    "$$\n",
    "\n",
    "| Campaign | Ad Spend ($x$) | Predicted Profit ($\\hat{y}$) |\n",
    "|----------|----------------|-------------------------------|\n",
    "| A        | 2              | 64.58                         |\n",
    "| B        | 3              | 68.37                         |\n",
    "| C        | 5              | 76.95                         |\n",
    "| D        | 7              | 85.53                         |\n",
    "| E        | 1              | 60.79                         |\n",
    "| F        | 4              | 72.16                         |\n",
    "| G        | 6              | 80.74                         |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Residuals\n",
    "\n",
    "Residuals:\n",
    "\n",
    "$$\n",
    "r = y - \\hat{y}\n",
    "$$\n",
    "\n",
    "| Campaign | Actual Profit ($y$) | Predicted ($\\hat{y}$) | Residual ($y - \\hat{y}$) |\n",
    "|----------|---------------------|------------------------|---------------------------|\n",
    "| A        | 65                  | 64.58                  | 0.42                      |\n",
    "| B        | 70                  | 68.37                  | 1.63                      |\n",
    "| C        | 75                  | 76.95                  | -1.95                     |\n",
    "| D        | 85                  | 85.53                  | -0.53                     |\n",
    "| E        | 60                  | 60.79                  | -0.79                     |\n",
    "| F        | 72                  | 72.16                  | -0.16                     |\n",
    "| G        | 78                  | 80.74                  | -2.74                     |\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Final Model\n",
    "\n",
    "$$\n",
    "\\hat{y} = 57 + 3.79x\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Interpretation\n",
    "\n",
    "- For each additional **\\$1,000 in advertising spend**, the **profit increases by approximately \\$3,790**\n",
    "- The small residuals suggest that the **linear model fits the data well**\n",
    "- Advertising is a **strong predictor of profit** in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0dd8a4",
   "metadata": {},
   "source": [
    "# üêç Implementation of Projection-Based Linear Regression for Predicting Profit from Advertising Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5099191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 1. Case Study Data ---\n",
    "# Ad Spend (independent variable X) and Profit (dependent variable Y)\n",
    "campaigns = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "x = [2, 3, 5, 7, 1, 4, 6]      # Ad Spend (in $1,000s)\n",
    "y = [65, 70, 75, 85, 60, 72, 78]  # Profit (in $1,000s)\n",
    "\n",
    "# --- 2. Create the Design Matrix ---\n",
    "X = np.column_stack((np.ones(len(x)), x))  # Add intercept column\n",
    "y_vec = np.array(y).reshape(-1, 1)\n",
    "\n",
    "# --- 3. Compute Œ≤ using Normal Equation ---\n",
    "XtX = X.T @ X\n",
    "XtX_inv = np.linalg.inv(XtX)\n",
    "Xt_y = X.T @ y_vec\n",
    "beta = XtX_inv @ Xt_y  # Coefficients [intercept, slope]\n",
    "\n",
    "# --- 4. Compute Predicted y (Projection) and Residuals ---\n",
    "y_hat = X @ beta\n",
    "residuals = y_vec - y_hat\n",
    "\n",
    "# --- 5. Pretty Printer ---\n",
    "def format_number(val):\n",
    "    if abs(val - round(val)) < 1e-10:\n",
    "        return str(int(round(val)))\n",
    "    else:\n",
    "        return f\"{val:.2f}\"\n",
    "\n",
    "def print_matrix(name, matrix, labels=None):\n",
    "    print(f\"\\n{name}:\")\n",
    "    for i, row in enumerate(matrix):\n",
    "        label = f\"{labels[i]}: \" if labels else \"\"\n",
    "        print(f\"{label}[\" + \"  \".join(format_number(val) for val in row) + \"]\")\n",
    "\n",
    "# --- 6. Display Results ---\n",
    "print_matrix(\"Design Matrix X\", X)\n",
    "print_matrix(\"Actual y (Profit)\", y_vec, campaigns)\n",
    "print_matrix(\"Predicted y (Projection ≈∑)\", y_hat, campaigns)\n",
    "print_matrix(\"Residuals (y - ≈∑)\", residuals, campaigns)\n",
    "print_matrix(\"Beta (Coefficients)\", beta)\n",
    "\n",
    "# --- 7. Model Summary ---\n",
    "intercept = beta[0, 0]\n",
    "slope = beta[1, 0]\n",
    "print(f\"\\nFinal Regression Equation:\")\n",
    "print(f\"≈∑ = {format_number(intercept)} + {format_number(slope)} √ó x (Ad Spend in $1,000s)\")\n",
    "print(\"\\nConclusion:\")\n",
    "print(f\"Each additional $1,000 of ad spend is predicted to increase the profit by about {format_number(slope)} thousand dollars.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a40eed",
   "metadata": {},
   "source": [
    "# üìä Linear Regression: Predicting Profit from Advertising Spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7011ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten vectors for plotting\n",
    "x = np.array(x)\n",
    "y_hat_flat = y_hat.flatten()\n",
    "\n",
    "# Plot\n",
    "plt.scatter(x, y, label='Actual Profit (y)', color='blue')\n",
    "plt.plot(x, y_hat_flat, label='Predicted Profit (≈∑)', color='red')\n",
    "plt.xlabel(\"Ad Spend (in $1,000s)\")\n",
    "plt.ylabel(\"Profit (in $1,000s)\")\n",
    "plt.title(\"Linear Regression: Predicting Profit from Advertising Spend\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72803f6",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## üìé Notes\n",
    "\n",
    "- The **projection matrix** $P = X(X^\\top X)^{-1}X^\\top$ maps any response vector $y$ onto the column space of $X$.\n",
    "- The predicted values $\\hat{y} = Py$ are the closest approximation to $y$ in that subspace (in terms of least squares).\n",
    "- The **residual vector** $r = y - \\hat{y}$ is orthogonal to the column space of $X$, meaning the model captures as much of the variation in $y$ as possible using the input features.\n",
    "- This method highlights the deep connection between **linear regression and linear algebra**, offering both computational and conceptual insight.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Benefits\n",
    "- **Clear geometric meaning**  \n",
    "  Regression is seen as projecting data onto a subspace, giving a visual and intuitive understanding.\n",
    "\n",
    "- **Strong linear algebra foundation**  \n",
    "  Uses matrix operations, orthogonality, and vector spaces to explain how regression works.\n",
    "\n",
    "- **Better understanding of residuals**  \n",
    "  Shows why the errors (residuals) are minimized and orthogonal to the model's predictions.\n",
    "\n",
    "- **Easy to extend**  \n",
    "  The method works well for multiple variables and more complex models.\n",
    "\n",
    "- **Practical and interpretable**  \n",
    "  Helps explain how changes in inputs (like ad spend) affect outputs (like profit) in real scenarios.\n",
    "\n",
    "- **Easy to implement in code**  \n",
    "  Fits naturally with Python and NumPy for educational or real-world use.\n",
    "---\n",
    "\n",
    "## üîö Conclusion\n",
    "\n",
    "This project shows that linear regression can be viewed not only as a statistical method, but also as a **geometric projection** in vector space.\n",
    "\n",
    "By projecting the outcome vector onto the space spanned by the input features:\n",
    "\n",
    "- We obtain the **best possible linear approximation** of the data.\n",
    "- We see that **ad spending** is a strong and measurable predictor of **profit** in this case.\n",
    "- The **projection method** provides a clear mathematical framework that improves both **understanding** and **model accuracy**.\n",
    "\n",
    "Understanding regression through projection builds a strong foundation for advanced topics in data science and machine learning.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
